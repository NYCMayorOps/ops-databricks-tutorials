{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7900fbae-7d63-4ed1-aa4d-816a17ba5a4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Working with Geopandas and Shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8128ff2e-e310-4ef4-ab64-0d64f02b5229",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Test this on a geospatially-enabled carto server with Sedona already installed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb02b63e-1f96-4fb9-8ece-f1e3a06a814a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sedona\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from sedona.sql.types import GeometryType\n",
    "from sedona.register import SedonaRegistrator\n",
    "from sedona.utils.adapter import Adapter\n",
    "from pyspark.sql.functions import col, expr\n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "424f3f2e-9d71-4ab2-9ad3-01ec2ece4808",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Sedona before 1.6.0 only works with Shapely 1.x. If you want to work with Shapely 2.x, please use Sedona no earlier than 1.6.0.\n",
    "\n",
    "If you use Sedona < 1.6.0, please use GeoPandas <= 0.11.1 since GeoPandas > 0.11.1 will automatically install Shapely 2.0. If you use Shapely, please use <= 1.8.5.\n",
    "\n",
    "**BUT** if you are using Sedona 1.7.0 like we are, use Geopandas > 1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78d91e96-0b7b-42a5-8e92-aaa1422e47b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Test Sedona Installation #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c363295c-197a-44df-8269-3b5bc8bfd964",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#test Sedona using SQL. Should return a point\n",
    "print(f\"sedona version: {sedona.version}\")\n",
    "df = spark.sql('SELECT ST_ASTEXT(ST_POINT(0,0)) AS test_point')\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6ddc91f-485f-49c1-81d7-2c32c0309f5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Some sources say you need to load the Sedona context. The way we set up the cluster, the context is loaded when the cluster starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a21b699-aab4-4fda-ae81-864e74b0a8ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#you don't need to do this. Sedona conext created when the Databricks cluster builds.\n",
    "from sedona.spark import *\n",
    "\n",
    "config = SedonaContext.builder().getOrCreate()\n",
    "sc = SedonaContext.create(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7075fbcf-4b0d-4a99-8ba7-b0a8eb3fdda1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Test Geopandas Installation #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90de60e4-d829-4cd0-9ee3-e8f9fb550936",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\" geopandas version: {gpd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f81fc9ba-57f9-4aa0-8153-100ab7e07672",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Test Apache Arrow. It is not enabled by default but should be enabled on the cluster.\n",
    "# It is necessary for reading geodataframes.\n",
    "arrow_enabled = spark.conf.get(\"spark.sql.execution.arrow.pyspark.enabled\")\n",
    "print(f\"Is Arrow enabled? {arrow_enabled}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3272730f-0fb0-4f85-b227-b8c86bde24d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read a map into a Pandas Geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "538d13cc-e77b-4441-98de-6e5767fa1501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#read geojson. Non-Delta tables can be stored easily in a volume instead of a Delta table.\n",
    "\n",
    "#can also work on zipped Shapefiles\n",
    "shapefile_path = '/Volumes/moo_ops_workspace/geospatial/geospatial_files_volume/Community Districts.zip'\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "gdf.info()\n",
    "\n",
    "geojson_path = '/Volumes/moo_ops_workspace/geospatial/geospatial_files_volume/BusinessImprovementDistrict.geojson'\n",
    "gdf = gpd.read_file(geojson_path)\n",
    "\n",
    "#dates will cause the geodataframe to break.\n",
    "try:\n",
    "   del gdf['created']\n",
    "   del gdf['modified']\n",
    "except: \n",
    "   pass\n",
    "gdf.info()\n",
    "print(gdf.geometry.head(4))\n",
    "m = folium.Map(location=[gdf.geometry.centroid.y.mean(), \n",
    "                         gdf.geometry.centroid.x.mean()\n",
    "                         ], \n",
    "               zoom_start=10\n",
    "            )\n",
    "folium.GeoJson(gdf.to_json()).add_to(m)\n",
    "display(m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5bf50be-104c-4232-84e1-d44e267025f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Write Geopandas GeoDataframeas geojson. ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81f00cc8-2af3-4aa6-ba97-b5bfb99ebef2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "https://sedona.apache.org/1.6.1/tutorial/sql/#load-geojson-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4126b68-2606-46a7-9626-57251dd0fce1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_path =  '/Volumes/moo_ops_workspace/geospatial/geospatial_files_volume/test.geojson'\n",
    "gdf.to_file(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7312233-39a7-45d2-8977-50378d0d68d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Interoperate with GeoPandas #\n",
    "Sedona Python has implemented serializers and deserializers which allows to convert Sedona Geometry objects into Shapely BaseGeometry objects. Based on that it is possible to load the data with geopandas from file (look at Fiona possible drivers) and create Spark DataFrame based on GeoDataFrame object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b631fa79-d9cd-4773-8737-1728eca4f7db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Geopandas to Sedona #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b444b81-cd59-4f1a-a9d1-4f987e6a2c0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You can use geopandas (which uses Shapely) to import geometry. Then you may pass the GeoPandas Geodataframe to Sedona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f44d14ed-2e6f-4e62-8de9-c421b5b7b85e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#read the GeoPandas Geodataframe into a Sedona Data Frame\n",
    "#convert the  the geometry as a well-known text geometry first.\n",
    "gdf_wkt = gdf.assign(geometry=gdf.geometry.apply(lambda geom: geom.wkt))\n",
    "gdf_wkt.info()\n",
    "\n",
    "#convert geodataframe into vanilla Spark dataframe.\n",
    "sdf = spark.createDataFrame(gdf_wkt)\n",
    "sdf.display()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a200af2-0282-4772-a750-58d0fb8d7fd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The data is now in a Spark dataframe. You need to parse the geometry column as a well-known text geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba069dbf-93be-4399-92ee-45bba9e84fbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#parse the geometry string column as wkt\n",
    "sedona_sdf_from_wkt = sdf.select(col(\"geometry\"), expr(\"ST_GeomFromWKT(geometry) AS geom\"))\n",
    "\n",
    "#can't display a geospatial dataframe unless you convert to text\n",
    "#sedona_sdf_from_wkt.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0fe4143-7eef-4533-9f6c-693a570cc86b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# you cannot display a geospatial dataframe\n",
    "sedona_sdf_from_wkt.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc897869-d244-4d5a-9705-12e07d954d51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Display a Sedona Geospatial Dataframe by converting it back to a GeoPandas GeoDataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5ee2867-47d1-4051-b3e1-8f0c5946c4f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To display a Sedona dataframe, convert it to GeoJSON. I don't know how to display directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bf47693-bc29-42cf-9e7d-71e55b5c123e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#convert it back to to wkt\n",
    "sdf_back_to_wkt = sedona_sdf_from_wkt.select(expr(\"ST_ASTEXT(geom) AS geometry\"))\n",
    "\n",
    "#convert it back to pandas\n",
    "sdf_to_pd = sdf_back_to_wkt.toPandas()\n",
    "\n",
    "#convert WKT string to Shapely geometry object using shapely.wkt\n",
    "pd_to_gdf = sdf_to_pd.copy()\n",
    "pd_to_gdf['geometry'] = sdf_to_pd['geometry'].apply(wkt.loads)\n",
    "\n",
    "#convert to pandas dataframe with shapely geometry back to a Geodataframe to get centroids.\n",
    "gdf = gpd.GeoDataFrame(pd_to_gdf, geometry='geometry')\n",
    "\n",
    "#plot using folium\n",
    "\n",
    "m = folium.Map(location=[gdf.geometry.centroid.y.mean(),\n",
    "                         gdf.geometry.centroid.x.mean()\n",
    "                         ],\n",
    "                zoom_start=10\n",
    "                )\n",
    "\n",
    "\n",
    "try:\n",
    "    folium.GeoJson(pd_to_gdf.to_json()).add_to(m)\n",
    "except OverflowError :\n",
    "    print(\"OverflowError: Maximum recursion level reached.\\n The map is too detailed.\\n Simplifying\")\n",
    "    gdf_simplified = gdf.simplify(tolerance=0.0001)\n",
    "    folium.GeoJson(gdf_simplified.to_json()).add_to(m)\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5709d733-35b7-4953-a7ce-80b849b9f63c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# From Spark Sedona to Geopandas #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81f8d493-b71a-4543-9ae1-302122317a4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# From Spark DataFrame to GeoPandas GeoDataframe#\n",
    "Convert the vanilla Spark Data Frame back into a Geodataframe for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a0d0583-e14b-49f8-92d8-d2d2ffa3a5c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "df_from_spark = sdf.toPandas()\n",
    "df_from_spark['geometry'] = df_from_spark['geometry'].apply(wkt.loads)\n",
    "df_from_spark.info()\n",
    "gdf_from_spark = gpd.GeoDataFrame(df_from_spark, geometry='geometry')\n",
    "m = folium.Map(location=[gdf_from_spark.geometry.centroid.y.mean(), \n",
    "                         gdf_from_spark.geometry.centroid.x.mean()\n",
    "                         ], \n",
    "               zoom_start=10\n",
    "            )\n",
    "folium.GeoJson(gdf_from_spark.to_json()).add_to(m)\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43404ece-d594-412d-8aeb-28f9d0362235",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b3971bb-e8b9-44f7-b5ff-a0eb7201dcd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01ecb01b-ca6a-45fb-aecb-c2e340f6fa28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Read geojson in to Sedona natively\n",
    "This doesn't work so well. **The easiest thing to do is read as geopandas and convert to Sedona.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ff6454d-808b-4017-ab62-102c4e3fdaec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c973182b-a8ec-4407-8449-f5c2b473b4d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "One way is to do spark.read.json. But this only imports it as a Spark Dataframe, not a geospatial dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "478cd1c1-f9bd-41c9-a413-4e11f6f47f8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    " 0   BIDID       76 non-null     int32   \n",
    " 1   BID         76 non-null     object  \n",
    " 2   SHAPE_AREA  76 non-null     float64 \n",
    " 3   SHAPE_LEN   76 non-null     float64 \n",
    " 4   borough     76 non-null     object  \n",
    " 5   geometry    76 non-null     geometry\n",
    " '''\n",
    "schema = \"BIDID INT, BID STRING, SHAPE_AREA DOUBLE, SHAPE_LEN DOUBLE, borough STRING, geometry STRING\"\n",
    "#schema = \"type string, crs string, totalFeatures long, features array<struct<type string, geometry string, properties map<string, string>>>\";\n",
    "#sdf = sedona.read.schema(schema).json(test_path)\n",
    "\n",
    "#sdf = sedona.read.schema(schema).json(test_path)\n",
    "sdf_from_geojson = spark.read.json(geojson_path)\n",
    "sdf_from_geojson.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd7685f6-d218-4278-90dd-4ef30437aec9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "as you can see, the file is corrupt. however, you can use the corrupt file to tweak the schema to get the correct results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "919a81d3-f4ae-4a8a-b9b3-db7bfc1f56d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#you may unpack the json with a select query. AI will speed this up.\n",
    "sdf_unpacked = sdf_from_geojson.select(\n",
    "    col(\"geometry.coordinates\")[0].alias(\"geometry\"),\n",
    "    col(\"properties.BIDID\").alias(\"BIDID\"),\n",
    "    col(\"properties.BID\").alias(\"BID\"),\n",
    "    col(\"properties.SHAPE_AREA\").alias(\"SHAPE_AREA\"),\n",
    "    col(\"properties.SHAPE_LEN\").alias(\"SHAPE_LEN\"),\n",
    "    col(\"properties.borough\").alias(\"borough\")\n",
    ")\n",
    "display(sdf_unpacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e39109d3-1783-49eb-aa48-291fe404018d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "But how do you convert an array of an array of strings to a Sedona geometry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6068b4e-3774-4447-af55-6eece6a3c3b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#this isn't working because geometry is packed inside a double array\n",
    "st_gdf = sdf_unpacked.withColumn(\"geometry_string\", expr(\"CAST(geometry AS STRING)\"))\n",
    "\n",
    "st_gdf = st_gdf.withColumn(\"geometry\",\n",
    "                           expr(\"ST_ASWKT(ST_GeomFromGeoJSON(CONCAT('{\\\"type\\\": \\\"Polygon\\\", \\\"coordinates\\\": ', geometry_string, '}')))\")\n",
    "                          )\n",
    "'''\n",
    "st_gdf = st_gdf.withColumn(\n",
    "    \"geometry\",\n",
    "    expr(\n",
    "        \"ST_ASWKT(ST_GeomFromGeoJSON(CONCAT('{\\\" \\\"type\\\": \\\"Polygon\\\", \\\"coordinates\\\": ', geometry_string, '\\\"}')))\"\n",
    "    )\n",
    ")\n",
    "'''\n",
    "#you cannot display this geospatially enabled geodataframe\n",
    "st_gdf.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f419451c-67a6-42e0-ad3c-39408fc10748",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Some other attempts at reading a geojson into Sedona that failed ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c05c193e-7b73-4fbd-bf85-2c640f3f20a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#this does not work. there is no spark source type called geojson\n",
    "sdf = spark.read.format(\"geojson\").load(map_path)\n",
    "display(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dd329b1-ccfc-4f8a-9156-2d9e0de8e36b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#there is no geojson method\n",
    "spark.read.geojson(map_path).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "240ddeeb-9229-464c-b9ae-88e6f71e47ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#this does not work\n",
    "from sedona.core.formatMapper import GeoJsonReader\n",
    "print(map_path)\n",
    "geojson_reader : GeoJsonReader = GeoJsonReader()\n",
    "sdf_direct = geojson_reader.readToGeometryRDD(spark, map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fcab3ee-13c5-43da-b199-6ae6a5635b67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#this is listed in the documentation but doesn't work\n",
    "geojson_reader.createSpatialRDD(spark, map_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6636c23-b07d-4dd5-aec8-e1aaaefd2518",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To display, convert it to pandas  "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Test Sedona and Geopandas",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
